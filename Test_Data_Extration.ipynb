{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ec6378f-613c-4f45-bb2a-300054ed8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb892c5d-5f42-4c3f-9117-b3c0f438a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "file_path = './truth_excel/test_all_studies_final.xlsx'\n",
    "workbook = load_workbook(file_path)\n",
    "sheet = workbook.active\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = sheet.values\n",
    "columns = next(data)\n",
    "df_truth = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "882505e9-defe-46d1-9c85-777326d152a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c63ffd2d-aa5f-4221-98c2-7316cdc8d859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rynn2008.pdf', 'lennox2003.pdf', 'kasper2014.pdf', 'hartford2007.pdf', 'boyer2004.pdf', 'merideth2012.pdf', 'mahablesh2013.pdf', 'davidson2004.pdf', 'pollock2001.pdf', 'nicolini2009.pdf', 'allgulander2004.pdf', 'pollock2008a.pdf', 'wu2011.pdf', 'bose2008.pdf', 'rickels2003.pdf', 'rothschild2012.pdf', 'stein2008.pdf', 'khan2011.pdf', 'alaka2014.pdf', 'ball2015.pdf', 'nimatoudis2004.pdf']\n"
     ]
    }
   ],
   "source": [
    "def get_file_names(directory):\n",
    "    \"\"\"Gets a list of file names in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file names.\n",
    "    \"\"\"\n",
    "\n",
    "    file_names = []\n",
    "    for entry in os.scandir(directory):\n",
    "        if entry.is_file():\n",
    "            file_names.append(entry.name)\n",
    "    return file_names\n",
    "\n",
    "directory_path = \"../Desktop/Testing\"\n",
    "file_names = get_file_names(directory_path)\n",
    "print(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a13d9-fae1-47e4-9843-6b127ec27a4d",
   "metadata": {},
   "source": [
    "# Pollock2008a was omitted due to heavy data discrepencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7405ba14-c2de-4101-ba3b-d9f17d089090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text and tables\n",
    "def extract_pdf_content(file_path):\n",
    "    text = \"\"\n",
    "    tables = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "            \n",
    "            # Extract tables\n",
    "            for table in page.extract_tables():\n",
    "                tables.append(pd.DataFrame(table))\n",
    "    return text, tables\n",
    "\n",
    "# Function to extract images\n",
    "def extract_images_from_pdf(file_path):\n",
    "    images = convert_from_path(file_path)\n",
    "    return images\n",
    "\n",
    "# Function to process images using OCR\n",
    "def process_images_with_ocr(images):\n",
    "    ocr_results = []\n",
    "    for img in images:\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        ocr_results.append(text)\n",
    "    return ocr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f52cb8b3-f0a9-4198-a143-a6f658291beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "def convert_pdf_to_base64_images(pdf_path, dpi=200, image_format='JPEG'):\n",
    "    images = convert_from_path(pdf_path, dpi=dpi)\n",
    "    base64_images = []\n",
    "    for img in images:\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format=image_format)\n",
    "        buffer.seek(0)\n",
    "        image_data = buffer.getvalue()\n",
    "        image_base64 = base64.b64encode(image_data).decode('utf-8')\n",
    "        base64_images.append(image_base64)\n",
    "    return base64_images\n",
    "\n",
    "def query_gpt4_full(text, tables, pdf_path):\n",
    "    # Convert all PDF pages to base64-encoded images\n",
    "    base64_images = convert_pdf_to_base64_images(pdf_path)\n",
    "    \n",
    "    structured_prompt_text = (\n",
    "        f\"Clinical Trial Report Analysis:\\n\\n\"\n",
    "        f\"Extracted Text:\\n{text}\\n\\n\"\n",
    "        f\"Extracted Tables:\\n{tables}\\n\\n\"\n",
    "        f\"This is a clinical trial report. For EACH intervention in the trial (including placebo), \"\n",
    "        f\"please extract the following characteristics and format the response as valid JSON using this exact example structure:\\n\\n\"\n",
    "        f\"Example format:\\n\"\n",
    "        f\"{{\\n\"\n",
    "        f'    \"Last Name of Main Author and Year\": \"Doe et al., 2021\",\\n'\n",
    "        f'    \"Full Population Sample Size\": \"451\",\\n'\n",
    "        f'    \"Intervention\": \"Duloxetine: 50 mg/day\",\\n'\n",
    "        f'    \"Main Race\": \"White\",\\n'\n",
    "        f'    \"Percent of Intervention Population that is Female (%)\": \"61.5\",\\n'\n",
    "        f'    \"Mean HAMA Score\": \"24.5\",\\n'\n",
    "        f'    \"Mean Population Age (Year)\": \"43.2\",\\n'\n",
    "        f'    \"Attrition Rate (%)\": \"30.2\",\\n'\n",
    "        f'    \"Full Sponsor Name\": \"ABC Pharmaceuticals\",\\n'\n",
    "        f'    \"Follow-up Time (Weeks)\": \"10\",\\n'\n",
    "        f'    \"Diagnostic Criteria\": \"DSM-IV\"\\n'\n",
    "        f\"}}\\n\\n\"\n",
    "        f\"'Full Population Sample Size' should refer to the TOTAL population enrolled in the study, across all interventions and groups, not just the population size for the specific intervention.\\n\"\n",
    "        f\"'Intervention' should be in mg/day, not any other unit of measurement.\\n\"\n",
    "        f\"'Follow-up Time' should refer to total length of the treatment period, omitting washout periods.\\n\"\n",
    "        f\"'Mean HAMA' should be the mean HAMA score at the beginning of the study for the specific intervention.\\n\"\n",
    "        f\"'Attrition Rate' should be % of patients who failed to complete the treatment after assignment\\n\"\n",
    "        f\" Make sure each JSON object follows this format exactly. For any missing or unavailable data, input 'NA'. If you are unsure about an answer, input 'NA'.\"\n",
    "    )\n",
    "\n",
    "    # Construct the message content as a list: first the text, then the images\n",
    "    message_content = []\n",
    "    message_content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": structured_prompt_text\n",
    "    })\n",
    "\n",
    "    # Add each page of the PDF as an image message\n",
    "    for img_b64 in base64_images:\n",
    "        message_content.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{img_b64}\"\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # Create the chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a data extraction assistant extracting data from clinical trial reports.\"},\n",
    "            {\"role\": \"user\", \"content\": message_content}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83219799-8ae8-4088-b9ad-831dce6a56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query_gpt4_text(text, tables, ocr_results):\n",
    "#     structured_prompt = (\n",
    "#         f\"Clinical Trial Report Analysis:\\n\\n\"\n",
    "#         f\"Extracted Text:\\n{text}\\n\\n\"\n",
    "#         f\"Extracted OCR Text from Images:\\n{ocr_results}\\n\\n\"\n",
    "#         f\"Extracted Tables:\\n{tables}\\n\\n\"\n",
    "#         f\"This is a clinical trial report. For EACH intervention in the trial (including placebo), please extract the following characteristics and format the response as valid JSON using this exact example structure:\\n\\n\"\n",
    "#         f\"Example format:\\n\"\n",
    "#         f\"{{\\n\"\n",
    "#         f'    \"Last Name of Main Author and Year\": \"Doe et al., 2021\",\\n'\n",
    "#         f'    \"Full Population Sample Size\": \"451\",\\n'\n",
    "#         f'    \"Intervention\": \"Duloxetine: 50 mg/day\",\\n'\n",
    "#         f'    \"Main Race\": \"White\",\\n'\n",
    "#         f'    \"Percent of Intervention Population that is Female (%)\": \"61.5\",\\n'\n",
    "#         f'    \"Mean HAMA Score\": \"24.5\",\\n'\n",
    "#         f'    \"Mean Population Age (Year)\": \"43.2\",\\n'\n",
    "#         f'    \"Attrition Rate (%)\": \"30.2\",\\n'\n",
    "#         f'    \"Full Sponsor Name\": \"ABC Pharmaceuticals\",\\n'\n",
    "#         f'    \"Follow-up Time (Weeks)\": \"10\",\\n'\n",
    "#         f'    \"Diagnostic Criteria\": \"DSM-IV\"\\n'\n",
    "#         f\"}}\\n\\n\"\n",
    "#         f\"'Full Population Sample Size' should refer to the TOTAL population enrolled in the study, across all interventions and groups, not just the population size for the specific intervention.\\n\"\n",
    "#         f\"'Intervention' should be in mg/day, not any other unit of measurement.\\n\"\n",
    "#         f\"'Follow-up Time' should refer to total length of the treatment period, omitting washout periods.\\n\"\n",
    "#         f\"'Mean HAMA' should be the mean HAMA score at the beginning of the study for the specific intervention.\\n\"\n",
    "#         f\"'Attrition Rate' should be % of patients who failed to complete the treatment after assignment\\n\"\n",
    "#         f\" Make sure each JSON object follows this format exactly. For any missing or unavailable data, input 'NA'. If you are unsure about an answer, input 'NA'.\"\n",
    "#     )\n",
    "#     response = completion = client.chat.completions.create(\n",
    "#         model=\"gpt-4o\",\n",
    "#         messages=[{\"role\": \"system\", \"content\": \"You are a data extraction assistant extracting data from clinical trial reports.\"},\n",
    "#                   {\"role\": \"user\", \"content\": structured_prompt}],\n",
    "#     )\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a48ceaa-6258-49cf-b977-3ef062ad7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Rename columns in df to match df_truth\n",
    "    df = df.rename(columns={\n",
    "        \"Last Name of Main Author and Year\": \"References\",\n",
    "        \"Full Population Sample Size\": \"Sample size\",\n",
    "        \"Main Race\": \"Main race\",\n",
    "        \"Intervention\": \"Interventions\",\n",
    "        \"Percent of Study Population that is Female (%)\": \"Female (%)\",\n",
    "        \"Percent of Intervention Population that is Female (%)\": \"Female (%)\",\n",
    "        \"Mean HAMA Score\": \"Mean HAMA\",\n",
    "        \"Mean Population Age (Year)\": \"Mean age (Year)\",\n",
    "        \"Attrition Rate (%)\": \"Attrition rate (%)\",\n",
    "        \"Full Sponsor Name\": \"Sponsor\",\n",
    "        \"Follow-up Time (Weeks)\": \"Follow-up time (weeks)\",\n",
    "        \"Diagnostic Criteria\": \"Diagnosis criteria\"\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe8d562a-ff81-4db4-b2c7-5bc3ef39c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_numerical_columns(df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Converts specified numerical columns to numeric types in a DataFrame.\n",
    "    Keeps 'NA' as a string and does not convert it to NaN.\n",
    "    \"\"\"\n",
    "    for col in numerical_cols:\n",
    "        if col in df.columns:\n",
    "            # Preserve 'NA' and convert the rest to numeric\n",
    "            df[col] = df[col].apply(lambda x: x if str(x).strip().lower() == \"na\" else pd.to_numeric(x, errors=\"coerce\"))\n",
    "    return df\n",
    "\n",
    "# Update the numerical columns list\n",
    "numerical_cols = [\"Sample size\", \"Female (%)\", \"Mean HAMA\", \"Mean age (Year)\", \"Attrition rate (%)\", \"Follow-up time (weeks)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5be5a1aa-5c9e-4c58-802e-2434a48102d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_interventions_and_diag(df):\n",
    "    \"\"\"\n",
    "    Normalizes the 'Interventions' column in the DataFrame for consistent filtering.\n",
    "    Replaces all dashes (e.g., en dash, em dash) with a standard hyphen.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"Interventions\"] = (\n",
    "        df[\"Interventions\"]\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\"–\", \"-\", regex=False)  # Replace en dash with hyphen\n",
    "        .str.replace(\"—\", \"-\", regex=False)  # Replace em dash with hyphen\n",
    "        .str.replace(\"\\u00a0\", \" \")  # Replace non-breaking space with regular space\n",
    "        .str.replace(r\":(?=\\d)\", \": \", regex=True)\n",
    "        .str.replace(r\"SR:\", \":\", regex = True)\n",
    "        .str.replace(r\"XR:\", \":\", regex = True)\n",
    "\n",
    "    )\n",
    "    df[\"Diagnosis criteria\"] = (\n",
    "    df[\"Diagnosis criteria\"]\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\"–\", \"-\", regex=False)  # Replace en dash with hyphen\n",
    "        .str.replace(\"—\", \"-\", regex=False)  # Replace em dash with hyphen\n",
    "        .str.replace(\"\\u00a0\", \" \")  # Replace non-breaking space with regular space\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f2116eb-5dd2-49d5-8b69-2520ecb591bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(df_truth, df):\n",
    "    grouped_truth = df_truth.groupby(\"References\")\n",
    "    grouped_pred = df.groupby(\"References\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for reference in grouped_truth.groups:\n",
    "        if reference in grouped_pred.groups:\n",
    "            # Get groups\n",
    "            truth_group = grouped_truth.get_group(reference)\n",
    "            pred_group = grouped_pred.get_group(reference)\n",
    "    \n",
    "            # Normalize and find common interventions\n",
    "            truth_interventions = set(truth_group[\"Interventions\"].tolist())\n",
    "            pred_interventions = set(pred_group[\"Interventions\"].tolist())\n",
    "            common_interventions = truth_interventions & pred_interventions  # Only common interventions\n",
    "    \n",
    "            for intervention in common_interventions:\n",
    "                # Filter for the specific intervention\n",
    "                truth_row = truth_group[truth_group[\"Interventions\"] == intervention]\n",
    "                pred_row = pred_group[pred_group[\"Interventions\"] == intervention]\n",
    "    \n",
    "                if not truth_row.empty and not pred_row.empty:\n",
    "                    truth_row = truth_row.iloc[0]\n",
    "                    pred_row = pred_row.iloc[0]\n",
    "    \n",
    "                    # Categorical columns\n",
    "                    categorical_cols = [\"Main race\"]\n",
    "                    categorical_match = {\n",
    "                        col: truth_row[col].strip().lower() == pred_row[col].strip().lower()\n",
    "                        for col in categorical_cols\n",
    "                    }\n",
    "    \n",
    "                    # Special handling for \"Diagnosis criteria\"\n",
    "                    diagnosis_criteria_truth = truth_row[\"Diagnosis criteria\"].strip().lower()\n",
    "                    diagnosis_criteria_pred = pred_row[\"Diagnosis criteria\"].strip().lower()\n",
    "                    categorical_match[\"Diagnosis criteria\"] = diagnosis_criteria_truth in diagnosis_criteria_pred\n",
    "\n",
    "                    # Special handling for \"Sponsor\"\n",
    "                    sponsor_truth = truth_row[\"Sponsor\"].strip().lower()\n",
    "                    sponsor_pred = pred_row[\"Sponsor\"].strip().lower()\n",
    "                    categorical_match[\"Sponsor\"] = sponsor_truth in sponsor_pred\n",
    "\n",
    "                    # Numerical columns\n",
    "                    numerical_cols = [\"Sample size\", \"Female (%)\", \"Mean HAMA\", \"Mean age (Year)\", \"Attrition rate (%)\", \"Follow-up time (weeks)\"]\n",
    "                    numerical_match = {}\n",
    "                    for col in numerical_cols:\n",
    "                        truth_val = truth_row[col]\n",
    "                        pred_val = pred_row[col]\n",
    "                        truth_is_na = str(truth_val).strip().lower() == \"na\"\n",
    "                        pred_is_na = str(pred_val).strip().lower() == \"na\"\n",
    "\n",
    "                        # Handle different scenarios for NA\n",
    "                        if truth_is_na and pred_is_na:\n",
    "                            numerical_match[col] = True  # Both are NA, match is True\n",
    "                        elif truth_is_na or pred_is_na:\n",
    "                            numerical_match[col] = False  # Only one is NA, match is False\n",
    "                        else:\n",
    "                            # Perform numerical comparison\n",
    "                            numerical_match[col] = np.isclose(\n",
    "                                float(truth_val), float(pred_val), atol=0.5, equal_nan=True\n",
    "                            )\n",
    "    \n",
    "                    # Collect results\n",
    "                    results.append({\n",
    "                        \"References\": reference,\n",
    "                        \"Interventions\": intervention,\n",
    "                        **categorical_match,\n",
    "                        **numerical_match,\n",
    "                    })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c325ac85-c800-4272-95d6-ef8beec86ac4",
   "metadata": {},
   "source": [
    "# Rynn 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52096f40-62bc-4092-9486-9d43508037d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../Desktop/Testing/rynn2008.pdf\"\n",
    "\n",
    "# Extract content from PDF\n",
    "rynn_2008_text, rynn_2008_tables = extract_pdf_content(file_path)\n",
    "\n",
    "# Query GPT-4\n",
    "structured_data_rynn_2008 = query_gpt4_full(rynn_2008_text, rynn_2008_tables, \"../Desktop/Testing/rynn2008.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9702ec-db6c-49cc-b63c-32c6bfeaecfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
